{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "from foldingdiff.tokenizer import Tokenizer\n",
    "from collections import defaultdict\n",
    "from foldingdiff.datasets import *\n",
    "from foldingdiff.algo import compute_rmsd\n",
    "os.chdir('/n/holylfs06/LABS/mzitnik_lab/Users/msun415/foldingdiff')\n",
    "from bin.encode import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified(t):\n",
    "    mod = []\n",
    "    for k, v in t.bond_to_token.items():\n",
    "        if isinstance(v[1], tuple):\n",
    "            mod.append(k)\n",
    "    return mod\n",
    "\n",
    "\n",
    "def compare(t1, t2):\n",
    "    return compute_rmsd(t1.compute_coords(), t2.compute_coords())\n",
    "\n",
    "\n",
    "def vis_images(*paths):\n",
    "    \"\"\"\n",
    "    Display an arbitrary number of images in a square-ish grid layout.\n",
    "\n",
    "    Parameters:\n",
    "    *paths: variable number of file paths to images\n",
    "    \"\"\"\n",
    "    n = len(paths)\n",
    "    if n == 0:\n",
    "        print(\"No images to display.\")\n",
    "        return\n",
    "\n",
    "    # Determine grid size (close to square)\n",
    "    n_cols = math.ceil(math.sqrt(n))\n",
    "    n_rows = math.ceil(n / n_cols)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "\n",
    "    # Flatten axes array for easy iteration\n",
    "    if isinstance(axes, plt.Axes):\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    # Display each image\n",
    "    for ax, path in zip(axes, paths):\n",
    "        img = mpimg.imread(path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(path.split(\"/\")[-1])\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for ax in axes[len(paths):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b91b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_ITERS = 500\n",
    "STEP_ITER = 10\n",
    "ratio = 10\n",
    "d = \"1751936564.1540673\" # bins 3\n",
    "# d = \"1751601353.4568286\" # bins 4\n",
    "# d = \"1751395339.1781707\"\n",
    "# d = \"1751395338.979964\"\n",
    "args = open(f\"./ckpts/{d}/args.txt\").readlines()\n",
    "for line in args:\n",
    "    print(line.rstrip('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = FullCathCanonicalCoordsDataset(\n",
    "    'repeat', use_cache=False, debug=False,\n",
    "    zero_center=False, toy=0, pad=512, secondary=False,\n",
    "    trim_strategy=\"discard\"\n",
    ")\n",
    "cleaned_structures = []\n",
    "for i, struc in enumerate(dataset.structures):\n",
    "    if (struc['angles']['psi']==struc['angles']['psi']).sum() < len(struc['angles']['psi'])-1:\n",
    "        print(f\"skipping {i}, {struc['fname']} because of missing dihedrals\")\n",
    "    else:\n",
    "        cleaned_structures.append(struc)\n",
    "dataset.structures = cleaned_structures\n",
    "ref = BPE(dataset.structures, \n",
    "            bins={1:3}, \n",
    "            bin_strategy='uniform', \n",
    "            save_dir=f'./ckpts/{d}',\n",
    "            rmsd_partition_min_size=2,\n",
    "            num_partitions=10,\n",
    "            compute_sec_structs=False, \n",
    "            plot_iou_with_sec_structs=False,                  \n",
    "            res_init=True)\n",
    "ref.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(path):\n",
    "    Ks, Ls, errs = [], [], []\n",
    "    for t in range(0, NO_ITERS, STEP_ITER):\n",
    "        path = f'./ckpts/{d}/bpe_iter={t}.pkl'\n",
    "        if not os.path.exists(path):\n",
    "            break\n",
    "        bpe = pickle.load(open(path, 'rb'))\n",
    "        usage = [len(t.bond_to_token) for t in bpe.tokenizers]\n",
    "        N = len(bpe.tokenizers)\n",
    "        K = len(bpe._tokens)\n",
    "        L = np.mean(usage)\n",
    "        errors = []\n",
    "        for i in tqdm(range(min(N, 10))):\n",
    "            try:\n",
    "                error = compare(bpe.tokenizers[i], ref.tokenizers[i])\n",
    "            except:\n",
    "                print(i)\n",
    "                raise\n",
    "            errors.append(error)\n",
    "        err = np.mean(errors)\n",
    "        errs.append(err)\n",
    "        Ks.append(K)\n",
    "        Ls.append(L)\n",
    "\n",
    "    Ks = np.array(Ks)\n",
    "    Ls = np.array(Ls)\n",
    "    errs = np.array(errs)\n",
    "    N = len(Ks)\n",
    "\n",
    "    # make figure + first (left) axis\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    # plot L vs K on left y-axis\n",
    "    x_diag = np.linspace(Ks.min(), Ks.max(), 100)\n",
    "    ax1.plot(x_diag, x_diag/ratio, linestyle='--', label=f\"L=K (K/L={ratio:.1f})\")\n",
    "    ax1.plot(Ks, Ls, marker='o', label=\"L vs K\", linewidth=2)\n",
    "    ax1.set_xlabel(\"K (Vocab Size) Each Round\")\n",
    "    ax1.set_ylabel(\"L  (#Motif-Tokens Per PDB)\")\n",
    "    ax1.set_xticks(Ks)\n",
    "\n",
    "    # create a second y-axis that shares the same x\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(Ks, errs, marker='x', linestyle=':', label=\"Error\", linewidth=2, color=\"tab:red\")\n",
    "    ax2.set_ylabel(\"Error\", color=\"tab:red\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "    # combine legends from both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
    "\n",
    "    ax1.set_title(f\"L vs K for N={N} w/ {len(Ks)} BPE rounds\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()  \n",
    "    plt.savefig(path) \n",
    "\n",
    "# plot(f'./ckpts/{d}/run.png') \n",
    "bpe = pickle.load(open(f'./ckpts/{d}/bpe_iter=0.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bpe.tokenizers), len(ref.tokenizers)\n",
    "# len(pickle.load(open(\"./ckpts/1751936564.1540673/bpe_iter=100.pkl\", \"rb\")).tokenizers)\n",
    "len(cleaned_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdffad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "path = f'./ckpts/{d}/bpe_iter={t}.pkl'\n",
    "bpe = pickle.load(open(path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25056d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(bpe.tokenizers)):\n",
    "    t = bpe.tokenizers[index]\n",
    "    for k in modified(t):\n",
    "        print(index, k, t.bond_to_token[k])\n",
    "\n",
    "        \n",
    "index = 6\n",
    "t = bpe.tokenizers[index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, length = 69, 6\n",
    "occur = (30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('../test.png')\n",
    "ref_path = os.path.abspath('../ref.png')\n",
    "bond_path = os.path.abspath('../test_bonds.png')\n",
    "ref_bond_path = os.path.abspath('../ref_bonds.png')\n",
    "t.visualize(path)\n",
    "ref.tokenizers[index].visualize(ref_path)\n",
    "t.visualize_bonds(start, length, bond_path)\n",
    "ref.tokenizers[index].visualize_bonds(start, length, ref_bond_path)\n",
    "vis_images(ref_bond_path, bond_path)\n",
    "# vis_images(*([bond_path] + [f'./ckpts/{d}/key_iter=0_{i}.png' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f66a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_images(ref_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.token_geo(start, length), bpe._tokens[occur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.tokenizers[index].fname, t.fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = t.token_geo(0, 3*t.n-1)\n",
    "tokenized = t.tokenize()\n",
    "repl = bpe.recover(tokenized)\n",
    "assert full == repl\n",
    "bpe.quantize(tokenized)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "struc = cleaned_structures[0]['angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.tokenizers[0].n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074202de",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_structures), len(ref.tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecbf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.tokenizers[0]._angles_and_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_structures[0]['angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.tokenizers[0].n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_structures[0]\n",
    "t.angles_and_dists[\"0C:1N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "t._angles_and_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bc3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from foldingdiff.tokenizer import *\n",
    "def init_structure(n):\n",
    "    angles = {\n",
    "        \"0C:1N\": [0. for _ in range(n)],\n",
    "        \"N:CA\": [0. for _ in range(n)],\n",
    "        \"CA:C\": [0. for _ in range(n)],\n",
    "        \"phi\": [np.nan for _ in range(n)],\n",
    "        \"psi\": [np.nan for _ in range(n)],\n",
    "        \"omega\": [np.nan for _ in range(n)],\n",
    "        \"tau\": [np.nan for _ in range(n)],\n",
    "        \"CA:C:1N\": [np.nan for _ in range(n)],\n",
    "        \"C:1N:1CA\": [np.nan for _ in range(n)]\n",
    "    }\n",
    "    idxes = sum([[i,i,i] for i in range(1, n+1)], [])\n",
    "    return {\n",
    "        \"angles\": pd.DataFrame(angles),\n",
    "        \"coords\": None,\n",
    "        \"c_beta\": None,\n",
    "        \"full_idxes\": idxes,\n",
    "        \"full_coords\": None,\n",
    "        \"side_chain\": None,\n",
    "        \"aa\": None,\n",
    "        \"fname\": None\n",
    "    }\n",
    "\n",
    "def recover_structure(repl):\n",
    "    n = len(repl[\"N:CA\"])\n",
    "    struc = init_structure(n)\n",
    "    # ref.tokenizers[0].angles_and_dists\n",
    "    struc[\"angles\"][\"N:CA\"].iloc[:-1] = repl[\"N:CA\"][1:]\n",
    "    struc[\"angles\"][\"CA:C\"].iloc[:-1] = repl[\"CA:C\"][1:]\n",
    "    struc[\"angles\"][\"0C:1N\"].iloc[:-1] = repl[\"0C:1N\"]\n",
    "    struc[\"angles\"][\"phi\"].iloc[1:] = repl[\"phi\"]\n",
    "    struc[\"angles\"][\"psi\"].iloc[:-1] = repl[\"psi\"]\n",
    "    struc[\"angles\"][\"omega\"].iloc[:-1] = repl[\"omega\"]\n",
    "    struc[\"angles\"][\"tau\"].iloc[:-1] = repl[\"tau\"][1:]\n",
    "    struc[\"angles\"][\"CA:C:1N\"].iloc[:-1] = repl[\"CA:C:1N\"]\n",
    "    struc[\"angles\"][\"C:1N:1CA\"].iloc[:-1] = repl[\"C:1N:1CA\"]\n",
    "    t_new = Tokenizer(struc)\n",
    "    t_new.bond_to_token = {}\n",
    "    cur = 0\n",
    "    for key, *pargs in tokenized:    \n",
    "        if key == \"MOTIF\":\n",
    "            token_id = pargs[0]\n",
    "            nb = Tokenizer.num_bonds(bpe._tokens[token_id]) \n",
    "            t_new.bond_to_token[cur] = (cur, token_id, nb)\n",
    "            cur += nb\n",
    "    return t_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f774bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fc27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
